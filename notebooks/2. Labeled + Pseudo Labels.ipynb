{"cells":[{"cell_type":"code","source":"import codecs\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torch import nn\nimport time\nimport pickle\nimport datetime\nimport random\n\n# Ensuring reproducibility\nseed = 0\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(seed)\nrandom.seed(seed)\n\nimport sys\nsys.path.insert(1, '/work/nlp-project')\nfrom scripts.read_write_data import read_processed_data, read_raw_data, load_data\nfrom models.classes import DataIterator, Batch, PolyDataIterator, F1_evaluator, F1_error_evaluator, Train2BiLSTM\n\nimport gensim.models\nGoogleEmbs = gensim.models.KeyedVectors.load_word2vec_format(\n                                '/work/nlp-project/models/GoogleNews-50k.bin', binary=True)","metadata":{"cell_id":"a01f9fe7392a41a58206b3724422ec70","source_hash":"3358f1ce","execution_start":1685035292335,"execution_millis":3899,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"PP_TRAIN_SET_PATH = \"nlp-project/data/pseudo/pseudo.conll\"\nTRAIN_SET_PATH = \"nlp-project/data/processed/train_splits/labeled.conll\"\nDEV_SET_PATH = \"nlp-project/data/processed/dev.conll\"","metadata":{"cell_id":"b539df0475014326861428b308e9afc7","source_hash":"51dbfd80","execution_start":1685032163007,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"documents, doc_labels, _, _ = load_data(TRAIN_SET_PATH)\ndev_docs, dev_labels, _, _ = load_data(DEV_SET_PATH)\n\n\npp_documents = []\npp_doc_labels = []\nfor words, labels in read_raw_data(PP_TRAIN_SET_PATH):\n    pp_documents.append(words)\n    pp_doc_labels.append(labels)","metadata":{"cell_id":"2e6ff25f59304b98b4db326014f20165","source_hash":"550f143f","execution_start":1685032163007,"execution_millis":364,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = Train2BiLSTM(hidden_size=10)\nmodel.fit(train=(documents, doc_labels),\n          train2=(pp_documents, pp_doc_labels),\n          print_metrics=False, \n          learning_rate=0.001,\n          dev = (dev_docs, dev_labels),\n          epochs=20)","metadata":{"cell_id":"9a6bfe8cf3014a61bf0d2864bd266717","source_hash":"6a106649","execution_start":1685021370567,"execution_millis":2646,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0, train: 0.004, dev: 0.000\nEpoch 1, train: 0.223, dev: 0.591\nEpoch 2, train: 0.761, dev: 0.639\nEpoch 3, train: 0.792, dev: 0.647\nEpoch 4, train: 0.805, dev: 0.654\nEpoch 5, train: 0.821, dev: 0.663\nEpoch 6, train: 0.831, dev: 0.663\nEpoch 7, train: 0.842, dev: 0.661\nEpoch 8, train: 0.850, dev: 0.662\nEpoch 9, train: 0.863, dev: 0.669\nEpoch 11, train: 0.884, dev: 0.666\nEpoch 12, train: 0.888, dev: 0.671\nEpoch 13, train: 0.891, dev: 0.673\nEpoch 14, train: 0.893, dev: 0.668\nEpoch 15, train: 0.893, dev: 0.672\nEpoch 16, train: 0.895, dev: 0.674\nEpoch 17, train: 0.896, dev: 0.672\nEpoch 18, train: 0.894, dev: 0.667\nEpoch 19, train: 0.893, dev: 0.668\n","output_type":"stream"}],"execution_count":0},{"cell_type":"code","source":"lr001_lininterpa_dev_f1 = [0.000,0.591,0.639,0.647,0.654,0.663,0.663,0.661,0.662,0.669,0.666,0.671,0.673,0.668,0.672,0.674,0.672,0.667,0.668]","metadata":{"cell_id":"1c24c4d6205b42dc9fb9eaa81c4bd520","source_hash":"bae26b0f","execution_start":1685035280876,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model2 = Train2BiLSTM(hidden_size=10)\nmodel2.fit(train=(documents, doc_labels),\n          train2=(pp_documents, pp_doc_labels),\n          print_metrics=False, \n          learning_rate=0.003,\n          dev = (dev_docs, dev_labels),\n          epochs=20,\n          alpha=0.5)\n\n# saving model 2:\ntorch.save(model2, \"nlp-project/models/Experiment2.pt\")","metadata":{"cell_id":"73b137c8a6a148db81dd4137cd69b938","source_hash":"10fd3f50","execution_start":1685044108993,"execution_millis":1371743,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0, train: 0.000, dev: 0.000\nEpoch 1, train: 0.304, dev: 0.605\nEpoch 2, train: 0.790, dev: 0.640\nEpoch 3, train: 0.817, dev: 0.645\nEpoch 4, train: 0.831, dev: 0.648\nEpoch 5, train: 0.840, dev: 0.652\nEpoch 6, train: 0.845, dev: 0.654\nEpoch 7, train: 0.848, dev: 0.658\nEpoch 8, train: 0.855, dev: 0.665\nEpoch 9, train: 0.867, dev: 0.670\nEpoch 10, train: 0.878, dev: 0.670\nEpoch 11, train: 0.883, dev: 0.674\nEpoch 12, train: 0.886, dev: 0.675\nEpoch 13, train: 0.889, dev: 0.671\nEpoch 14, train: 0.891, dev: 0.673\nEpoch 15, train: 0.894, dev: 0.675\nEpoch 16, train: 0.896, dev: 0.675\nEpoch 17, train: 0.897, dev: 0.678\nEpoch 18, train: 0.898, dev: 0.673\nEpoch 19, train: 0.900, dev: 0.678\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"lr003_a5_dev_f1 = [0.000,0.595,0.634,0.649,0.655,0.658,0.669,0.667,0.671,0.669,0.671,0.675,0.674,0.671,0.670,0.676,0.678,0.673,0.677,0.674]","metadata":{"cell_id":"106e5e66dd844758b3913c294fd4cab8","source_hash":"f01bdd26","execution_start":1685035309366,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model3 = Train2BiLSTM(hidden_size=10)\nmodel3.fit(train=(documents, doc_labels),\n          train2=(pp_documents, pp_doc_labels),\n          print_metrics=False, \n          learning_rate=0.003,\n          dev = (dev_docs, dev_labels),\n          epochs=20,\n          alpha=0.1)","metadata":{"cell_id":"431780dd482f4f5b9080c2dd4007b0e8","source_hash":"db684873","execution_start":1685041795797,"execution_millis":223640,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0, train: 0.000, dev: 0.000\nEpoch 1, train: 0.012, dev: 0.112\nEpoch 2, train: 0.703, dev: 0.642\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model3 \u001b[38;5;241m=\u001b[39m Train2BiLSTM(hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpp_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpp_doc_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mprint_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.003\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/work/nlp-project/models/classes.py:485\u001b[0m, in \u001b[0;36mTrain2BiLSTM.fit\u001b[0;34m(self, train, train2, dev, epochs, print_metrics, learning_rate, alpha)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m labeled, paraphrased \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoly_data_iterator([padded_documents, pseudo_docs], \n\u001b[1;32m    484\u001b[0m                                                     [padded_labels, pseudo_labels]):\n\u001b[0;32m--> 485\u001b[0m     pred_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabeled\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     pred_pseudo_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(inputs\u001b[38;5;241m=\u001b[39mparaphrased[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# probability distribution for each tag across all words\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;66;03m# pred_tags = pred_tags.view(-1, self.n_labels)\u001b[39;00m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# pred_pseudo_tags = pred_pseudo_tags.view(-1, self.n_labels)\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# true label for each word\u001b[39;00m\n","File \u001b[0;32m/work/nlp-project/models/classes.py:321\u001b[0m, in \u001b[0;36mTrain1BiLSTM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    Implements a forward pass through the BiLSTM.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    inputs are a batch (list) of sentences.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     word_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_google_embeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     lstm_result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(word_embeds)\n\u001b[1;32m    323\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_result)\n","File \u001b[0;32m/work/nlp-project/models/classes.py:338\u001b[0m, in \u001b[0;36mTrain1BiLSTM._get_google_embeds\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m             embed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m300\u001b[39m)  \u001b[38;5;66;03m# the word is not in the model dictionary, so use zero vector\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m         sentence_embeds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((embeddings, sentence_embeds), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(inputs), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":29},{"cell_type":"code","source":"lr003_a1_dev_f1 = model3.dev_f1_log","metadata":{"cell_id":"c8c16612ce094f9fadbef62702829823","source_hash":"cae0bd15","execution_start":1685035133750,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dev_f1s = [lr001_lininterpa_dev_f1[:19], lr003_a5_dev_f1[:19], lr003_a1_dev_f1[:19]]\n\ndev_f1s","metadata":{"cell_id":"d03403c4218a47929b97be54cb436354","source_hash":"cd68ea2d","execution_start":1685036004852,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"[[0.0,\n  0.591,\n  0.639,\n  0.647,\n  0.654,\n  0.663,\n  0.663,\n  0.661,\n  0.662,\n  0.669,\n  0.666,\n  0.671,\n  0.673,\n  0.668,\n  0.672,\n  0.674,\n  0.672,\n  0.667,\n  0.668],\n [0.0,\n  0.595,\n  0.634,\n  0.649,\n  0.655,\n  0.658,\n  0.669,\n  0.667,\n  0.671,\n  0.669,\n  0.671,\n  0.675,\n  0.674,\n  0.671,\n  0.67,\n  0.676,\n  0.678,\n  0.673,\n  0.677],\n [0,\n  0.6277541553923464,\n  0.6399691952252599,\n  0.6420038535645471,\n  0.6438461538461538,\n  0.6446407990779869,\n  0.6563944530046225,\n  0.655436447166922,\n  0.6610234705656022,\n  0.6648564778898371,\n  0.66873786407767,\n  0.6666666666666666,\n  0.6661496704148896,\n  0.6674427629025999,\n  0.6723470178156468,\n  0.6635730858468677,\n  0.663839629915189,\n  0.662848415425735,\n  0.6610494063577173]]"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b2f14aee-af04-4db5-af55-57a3a58b9f40' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"7331828764d347c18a9120b83ad63f8d","deepnote_execution_queue":[]}}