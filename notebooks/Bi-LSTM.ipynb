{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "486fc4764fab416ca01b850bac10a533",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5660,
    "execution_start": 1680012243503,
    "output_cleared": false,
    "source_hash": "59e1d38b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"nlp_project\")\n",
    "from nlp_project.scripts.read_write_data import read_processed_data\n",
    "\n",
    "import gensim.models\n",
    "GoogleEmbs = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "                                'nlp_project/models/GoogleNews-50k.bin', binary=True)\n",
    "\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "e699457ccd394d35b83ab8893304a853",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1680008346680,
    "output_cleared": false,
    "source_hash": "629f134f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"nlp_project/data/processed/train.conll\"\n",
    "DEV_PATH = \"nlp_project/data/processed/dev.conll\"\n",
    "TEST_PATH = \"nlp_project/data/processed/test.conll\"\n",
    "\n",
    "PAD = \"<PAD>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "46884a11d6a842ecb140fc4a63544be5",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1424fe352fa94c6b963206177323ed31",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "8e396a4916164bf0a219ffefbe61fa7e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 671,
    "execution_start": 1680008346691,
    "output_cleared": false,
    "source_hash": "86d792f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "doc_labels = []\n",
    "for words, labels, _, _ in read_processed_data(TRAIN_PATH):\n",
    "    documents.append(words)\n",
    "    doc_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "9d9ee71f29e24b14899bc0fde2ee1bb6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1680008347366,
    "output_cleared": false,
    "source_hash": "27aadbe7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:\n",
      "['My', 'dad', 'just', 'does', \"n't\", 'understand', '?']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['Ugh', 'my', 'dad', 'is', 'so', 'stupid', '...', 'he', 'just', 'does', \"n't\", 'understand', 'anything', '!']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['I', 'have', '5', 'sisters', 'and', 'so', 'including', 'my', 'mom', '...', 'he', 'is', 'the', 'only', 'guy', 'in', 'a', 'house', 'of', 'six', 'females', '.']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['Now', 'I', \"'m\", 'the', 'youngest', 'and', 'I', 'just', 'got', 'my', 'period', 'so', 'now', 'we', 'all', 'have', 'ours', 'and', 'he', 'thinks', 'it', \"'s\", 'a', 'good', 'thing', '?']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['He', \"'s\", 'always', 'like', '\"', 'ohh', 'you', 'must', 'be', 'so', 'happy', 'to', 'finally', 'have', 'yours', ',', 'I', 'wish', 'I', 'had', 'mine', '!', '\"', 'and', 'he', 'is', \"n't\", 'even', 'joking', '.']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['I', 'think', 'just', 'living', 'in', 'a', 'house', 'with', 'so', 'many', 'girls', 'is', 'making', 'him', 'go', 'crazy', '?']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['Yep', ',', 'the', 'females', 'are', 'just', 'getting', 'to', 'him', '...', 'dads', '..']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['Do', \"n't\", 'blame', 'him', 'please', ',', 'he', 'feels', 'lonely', 'and', 'wants', 'to', 'show', 'his', 'attention', 'to', 'all', 'of', 'you', 'to', 'look', 'after', 'you', ',', 'please', 'forgive', 'and', 'sympathy', 'if', 'he', 'miss', 'something', '.']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['I', 'am', 'sorry', 'for', 'him', ',', 'he', 'is', 'a', 'good', 'dad']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      "Document:\n",
      "['Equine', 'collages', 'uk', 'NEED', 'HELP', '!!!?']\n",
      "\n",
      "Matching labels:\n",
      "['0', '0', '1', '0', '0', '0'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc, labels in zip(documents[:10], doc_labels[:10]):\n",
    "    print(\"Document:\")\n",
    "    print(doc)\n",
    "    print(\"\\nMatching labels:\")\n",
    "    print(labels, '\\n\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8749313e34924f78a2c5d04f9ec18795",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Creating vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a7ba5fa8c96c4566af12f9cc860d9c47",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1680008347377,
    "output_cleared": false,
    "source_hash": "95efad92",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(documents: List[List[str]], pad_token: str = None) -> Dict[str, int]:\n",
    "    vocab = {pad_token: 0} if pad_token else {}\n",
    "    for doc in documents:\n",
    "        for token in doc:\n",
    "            vocab[token] = vocab.get(token, len(vocab))\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def reverse_dict(collection: Dict[Any, Any]) -> Dict[Any, Any]:\n",
    "    reverse = {}\n",
    "    for k, v in collection.items():\n",
    "        reverse[v] = k\n",
    "        \n",
    "    return reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "fd0bbb1bb1ae47b99bdaeea7cd60e213",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 134,
    "execution_start": 1680008347378,
    "output_cleared": false,
    "source_hash": "b712d33d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "word2idx = create_vocabulary(documents=documents, pad_token=PAD)\n",
    "idx2word = reverse_dict(collection=word2idx)\n",
    "label2idx = create_vocabulary(documents=doc_labels)\n",
    "idx2label = reverse_dict(collection=label2idx)\n",
    "\n",
    "print(\"word2idx len:\", len(word2idx))\n",
    "print(\"idx2word len:\", len(idx2word))\n",
    "print(\"label2idx len:\", len(label2idx))\n",
    "print(\"idx2label len:\", len(idx2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e272e94c8ed941158a71e3b4d17d1b8e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1680008347568,
    "output_cleared": false,
    "source_hash": "ab9a0935",
    "tags": []
   },
   "outputs": [],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7d62fab3cef142bf8c73251115687d5d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1680008347581,
    "output_cleared": false,
    "source_hash": "4ead9867",
    "tags": []
   },
   "outputs": [],
   "source": [
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8f7f9d6918864b9e84581f860259edaf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 224,
    "execution_start": 1680008347638,
    "output_cleared": false,
    "source_hash": "69d9ab25",
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_documents = [[word2idx[token] for token in doc] for doc in documents]\n",
    "enc_doc_labels = [[label2idx[label] for label in labels] for labels in doc_labels]\n",
    "\n",
    "for doc, labels in zip(enc_documents[:10], enc_doc_labels[:10]):\n",
    "    print(\"Document:\")\n",
    "    print(doc)\n",
    "    print(\"\\nMatching labels:\")\n",
    "    print(labels, '\\n\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "495ef8c33983469cb3bc273643965053",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Preparing input data - padding input data and using Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7310828934e44f92932cee1ca6b69ecc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1680008347873,
    "output_cleared": false,
    "source_hash": "2a7adac2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_encoding_matrix(collection: List[List[int]], pad_token_idx: str, max_len: int = None):\n",
    "    if not max_len:\n",
    "        max_len = max([len(x) for x in collection])\n",
    "\n",
    "    to_series = [pd.Series(el) for el in collection]\n",
    "    enc_matrix = (pd.concat(to_series, axis=1)\n",
    "                    .reindex(range(max_len))\n",
    "                    .fillna(pad_token_idx)\n",
    "                    .astype('int16')\n",
    "                    .T)\n",
    "\n",
    "    return enc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b0cbd484e637414680f6b0bb83059b25",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11530,
    "execution_start": 1680008347888,
    "output_cleared": false,
    "source_hash": "2ea12527",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in enc_documents])\n",
    "\n",
    "enc_document_matrix = create_encoding_matrix(enc_documents, word2idx[PAD], max_len=max_len)\n",
    "enc_label_matrix = create_encoding_matrix(enc_doc_labels, label2idx['0'], max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "63d56480d0524b91be9865d8caa58cd2",
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 1253,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 59,
    "execution_start": 1680008671954,
    "output_cleared": false,
    "source_hash": "25cc34a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_document_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8880113a0ca2486a8f515f0cb6a3221d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 116,
    "execution_start": 1680008359434,
    "output_cleared": false,
    "source_hash": "cf95e7fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4b8179e784d74e50a61ea1975995cb16",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1680008359557,
    "output_cleared": false,
    "source_hash": "24a08753",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_documents = torch.tensor(enc_document_matrix.to_numpy(), dtype=torch.long)\n",
    "input_labels = torch.tensor(enc_label_matrix.to_numpy(), dtype=torch.long)\n",
    "\n",
    "print(input_documents)\n",
    "print(input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e12f7bd414164efa8c35511ad115d4dc",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Batch Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d0265506e96a4024a1279c8328f0b59f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1680008359578,
    "output_cleared": false,
    "source_hash": "43c39c1d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Batch:\n",
    "    inputs: Tensor\n",
    "    targets: Tensor\n",
    "\n",
    "class DataIterator:\n",
    "    \n",
    "    def __init__(self, batch_size=32):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __call__(self, inputs: Tensor, targets: Tensor) -> Batch:\n",
    "        intervals = np.arange(0, len(inputs), self.batch_size)\n",
    "        for start in intervals:\n",
    "            end = start + self.batch_size\n",
    "            batch_inputs = inputs[start: end]\n",
    "            batch_targets = targets[start: end]\n",
    "            \n",
    "            yield Batch(batch_inputs, batch_targets)\n",
    "\n",
    "data_iterator = DataIterator()\n",
    "for batch in data_iterator(input_documents, input_labels):\n",
    "    print(batch.inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1abb4b393fb945218c8b74ce4a4b523a",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3de992f3d503487b84680c1ab70bbe56",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 20,
    "execution_start": 1680008359587,
    "source_hash": "d10b23ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "LSTM_HIDDEN = 50\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 20\n",
    "\n",
    "class BaselineLSTM(torch.nn.Module):\n",
    "    def __init__(self, n_words, n_labels):\n",
    "        super().__init__()\n",
    "        self.n_words = n_words\n",
    "        self.n_labels = n_labels\n",
    "        # self.embeds = nn.Embedding(n_words, EMBEDDING_DIM)\n",
    "        self.lstm = nn.LSTM(input_size=EMBEDDING_DIM, hidden_size=LSTM_HIDDEN, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(in_features=2 * LSTM_HIDDEN, out_features=n_labels)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        word_embeds = self._get_embeds(inputs)\n",
    "        word_embeds = nn.Dropout(p=0.2)(word_embeds)\n",
    "        lstm_result, _ = self.lstm(word_embeds)\n",
    "        lstm_result = nn.Dropout(p=0.3)(lstm_result)\n",
    "        tags = self.linear(lstm_result)\n",
    "        log_probs = F.softmax(tags)\n",
    "        return log_probs\n",
    "    \n",
    "    def _get_embeds(self, inputs):  # inputs of shape (32 sentences,150 tokens)\n",
    "        embeddings = torch.Tensor()\n",
    "        for sentence in inputs:\n",
    "            sentence_embeds = torch.Tensor()\n",
    "        \n",
    "            for word in sentence:\n",
    "                try:\n",
    "                    embed = torch.from_numpy(GoogleEmbs.get_vector(word))\n",
    "                except KeyError:\n",
    "                    embed = torch.zeros(300)\n",
    "                sentence_embeds = torch.cat((sentence_embeds, embed), dim=0)\n",
    "\n",
    "            embeddings = torch.cat((embeddings, sentence_embeds), dim=0)\n",
    "        return embeddings.view(len(inputs), -1, EMBEDDING_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a2efe74a9b23464fa044d07649a109e7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1680008359618,
    "source_hash": "fc5e45d7"
   },
   "outputs": [],
   "source": [
    "TRAIN_AND_SAVE = False  # 'False' stops this block from running when running the notebook\n",
    "\n",
    "if TRAIN_AND_SAVE:\n",
    "\n",
    "    model = BaselineLSTM(len(idx2word), len(idx2label))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_func = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        \n",
    "        total_tags = 0\n",
    "        matched_tags = 0\n",
    "        epoch_loss = 0\n",
    "        for i, batch in enumerate(data_iterator(input_documents, input_labels)):\n",
    "            pred_tags = model.forward(inputs=batch.inputs)\n",
    "            \n",
    "            # probability distribution for each tag across all words\n",
    "            pred_tags = pred_tags.view(-1, model.n_labels)\n",
    "            \n",
    "            # true label for each word\n",
    "            targets = batch.targets.flatten() \n",
    "            \n",
    "            batch_loss = loss_func(pred_tags, targets)\n",
    "            epoch_loss += batch_loss.item()\n",
    "            \n",
    "            # optimization\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # proportion of matched tags\n",
    "            for pred_tag, true_tag in zip(pred_tags, targets):\n",
    "                pred_tag_idx = torch.argmax(pred_tag)\n",
    "                if pred_tag_idx == true_tag:\n",
    "                    matched_tags +=1\n",
    "                total_tags += 1\n",
    "            \n",
    "            # validation loss\n",
    "            # model.eval()\n",
    "            # pred_dev_tags = model(dev_input)\n",
    "            \n",
    "            # pred_dev_tags = pred_dev_tags.view(-1, model.n_tags)\n",
    "            # true_dev_tags = dev_labels.flatten()\n",
    "            \n",
    "            # val_loss = loss_func(pred_dev_tags, true_dev_tags).item()\n",
    "                            \n",
    "        print(f\"Epoch {epoch} loss: {epoch_loss:.2f},  total tags matched: {matched_tags / total_tags * 100:.2f}%\")\n",
    "\n",
    "    # Save the model\n",
    "    mili_time = round(time.time() * 1000)\n",
    "    file_name = f\"nlp_project/models/model_{mili_time}.pkl\"\n",
    "    pickle.dump(model, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e77072ead06a472cac4167fe24844bd3",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "cd7c75bbc05d4adba8d27ac0445e44c9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1680008359651,
    "source_hash": "ffb4fc28"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'BaselineLSTM' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23188\\2764168872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# loading model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nlp_project/models/model_1679946334736.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'BaselineLSTM' on <module '__main__'>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\logging\\__init__.py\", line 1029, in emit\n",
      "    self.flush()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\logging\\__init__.py\", line 1009, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 22] Invalid argument\n",
      "Call stack:\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 463, in dispatch_queue\n",
      "    self.log.exception(\"Error in message handler\")\n",
      "Message: 'Error in message handler'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "# loading model\n",
    "with open('nlp_project/models/model_1679946334736.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "58bf3776c3f94bffae583292cccc2569",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 65,
    "execution_start": 1680008359666,
    "source_hash": "786af917"
   },
   "outputs": [],
   "source": [
    "dev_documents = []\n",
    "dev_labels = []\n",
    "for words, labels, _ ,_ in read_processed_data(DEV_PATH):\n",
    "    dev_documents.append(words)\n",
    "    dev_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7065c050b8394fccb602b5d484401ab8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1680008604850,
    "source_hash": "9e638971"
   },
   "outputs": [],
   "source": [
    "# enc_dev_documents = [[word2idx.get(token, '<PAD>') for token in doc] for doc in dev_documents]\n",
    "# enc_dev_labels = [[label2idx.get(label, '') for label in labels] for labels in dev_labels]\n",
    "\n",
    "\n",
    "# enc_dev_document_matrix = create_encoding_matrix(enc_dev_documents, word2idx[PAD], max_len=max_len)\n",
    "# enc_dev_label_matrix = create_encoding_matrix(enc_dev_labels, label2idx['0'], max_len=max_len)\n",
    "\n",
    "# dev_inputs = torch.Tensor(enc_dev_document_matrix.to_numpy(), dtype=torch.long)\n",
    "# dev_labels = torch.Tensor(enc_dev_label_matrix.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7b013d00d255402ea024839c74a40cf8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "ef947af2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "TypeError: object NoneType can't be used in 'await' expression\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\logging\\__init__.py\", line 1029, in emit\n",
      "    self.flush()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\logging\\__init__.py\", line 1009, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 22] Invalid argument\n",
      "Call stack:\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\users\\krzys\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 463, in dispatch_queue\n",
      "    self.log.exception(\"Error in message handler\")\n",
      "Message: 'Error in message handler'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "# pred_dev_tags = model(dev_inputs).view(-1, model.n_tags)\n",
    "# true_dev_tags = dev_labels.flatten()\n",
    "# val_loss = loss_func(pred_dev_tags, true_dev_tags).item()\n",
    "# print(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b2f14aee-af04-4db5-af55-57a3a58b9f40' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9c1c0588a70241539020d020895a3606",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
