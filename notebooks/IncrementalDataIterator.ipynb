{"cells":[{"cell_type":"markdown","source":"For each batch we need the proportion of pseudo labels to adjust the loss accordingly","metadata":{"cell_id":"973c54a367ca45e6b7a1a6940194a607","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"from __future__ import annotations\n\nimport numpy as np\nimport torch\n\nfrom typing import Callable, Tuple\nfrom torch import Tensor\n\nfrom typing import Iterator\n\n\nclass IncDataLoader:\n    \"\"\"\n    Data loader that gradually increases the amount of pseudo data in the training data.\n    \"\"\"\n    current_data: Tensor\n    current_labels: Tensor\n\n    def __init__(self, labeled_data: Tensor, labels: Tensor, pseudo_data: Tensor, pseudo_labels: Tensor, n_epochs: int) -> None:\n        self.lab_data = labeled_data\n        self.labels = labels\n        self.ps_data = pseudo_data\n        self.ps_labels = pseudo_labels\n        self.n_epochs = n_epochs\n\n        self.ratio_func = lambda step, loader: step / loader.n_epochs\n        self.step = 0\n\n    def __call__(self) -> Tuple[Tensor, Tensor]:\n        \"\"\" Returns labeled data/labels enriched with a number of samples from the pseudo data/labels. \"\"\"\n\n        # number of pseudo samples to use\n        n_pseudo = self.get_pseudo_number()\n\n        # indexes of those random samples\n        pseudo_idx = torch.randperm(len(self.ps_labels))[:n_pseudo]\n\n        # subset of pseudo data and their labels\n        ps_sub_data, ps_sub_labels = self.ps_data[pseudo_idx], self.ps_labels[pseudo_idx]\n\n        # concatenate labeled data and the subset of pseudo data\n        self.current_data = torch.cat((self.lab_data, ps_sub_data), 0)\n        self.current_labels = torch.cat((self.labels, ps_sub_labels))\n        \n        return self.current_data, self.current_labels\n    \n    def get_pseudo_ratio(self) -> float:\n        \"\"\" Returns the ratio of pseudo labels applied to the data. \"\"\"\n        return self.ratio_func(self.step, self)\n\n    def get_pseudo_number(self) -> int:\n        \"\"\" Returns the number of pseudo labels being currently used. \"\"\"\n        return round(len(self.ps_data) * self.get_pseudo_ratio())\n\n    def get_total_pseudo_ratio(self) -> float:\n        \"\"\" Returns the proportion of pseudo labels in the returned dataset \"\"\"\n        return self.get_pseudo_number() / len(self.current_data)\n\n    def set_ratio_func(self, func: Callable[[int, IncDataLoader], float]) -> None:\n        \"\"\" Set a function of time that will be used to calculate the proportion of pseudo data \"\"\"\n        self.ratio_func = func\n\n    def update(self):\n        \"\"\" Call this after each epoch to update the amount of pseudo data. \"\"\"\n        self.step += 1","metadata":{"cell_id":"3942fbcbf2d14953bd8d190c8b53ae2b","source_hash":"2e13e41d","execution_start":1683131554535,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# generate a 20 encoded sentences, each sentence consisting of 12 tokens\nlabeled_data = torch.randint(low=0, high=5, size=(5, 5))\nlabels = torch.randint(low=0, high=5, size=(5,))\n\n# generate 10 encoded pseudo sentences\npseudo_data = torch.randint(low=6, high=10, size=(5, 5))\npseudo_labels = torch.randint(low=6, high=10,a size=(5,))","metadata":{"cell_id":"f8a19208a3b14e55a78c537c30a7a513","source_hash":"38e64afc","execution_start":1683133424524,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":47},{"cell_type":"code","source":"print(labeled_data.shape)\nlabeled_data","metadata":{"cell_id":"fbcb8baaa7954a8bb77480615f6c1a16","source_hash":"5663d24d","execution_start":1683133429104,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"torch.Size([5, 5])\n","output_type":"stream"},{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"tensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0]])"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"data_loader = IncDataLoader(\n    labeled_data=labeled_data,\n    labels=labels,\n    pseudo_data=pseudo_data,\n    pseudo_labels=pseudo_labels,\n    n_epochs=10  # with the default linear function we should see 10% increase of pseudo data each epoch\n)\n\nfor epoch in range(11):\n    data, labs = data_loader()\n    print(\"Epoch\", epoch)\n    print(\"No. pseudo samples:\", data_loader.get_pseudo_number())\n    print(\"theoretical ratio of pseudo data included:\", data_loader.get_pseudo_ratio())\n    print(\"% of pseudo data in the dataset:\", data_loader.get_total_pseudo_ratio())\n    print(\"Dataset size:\", len(data))\n    print(data)\n    print()\n    data_loader.update()","metadata":{"cell_id":"137d4bdd382544c2bd041db292a0fb71","source_hash":"682bdb2d","execution_start":1683133527462,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0\nNo. pseudo samples: 0\ntheoretical ratio of pseudo data included: 0.0\n% of pseudo data in the dataset: 0.0\nDataset size: 5\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0]])\n\nEpoch 1\nNo. pseudo samples: 0\ntheoretical ratio of pseudo data included: 0.1\n% of pseudo data in the dataset: 0.0\nDataset size: 5\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0]])\n\nEpoch 2\nNo. pseudo samples: 1\ntheoretical ratio of pseudo data included: 0.2\n% of pseudo data in the dataset: 0.16666666666666666\nDataset size: 6\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [8, 9, 9, 7, 9]])\n\nEpoch 3\nNo. pseudo samples: 2\ntheoretical ratio of pseudo data included: 0.3\n% of pseudo data in the dataset: 0.2857142857142857\nDataset size: 7\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 7, 7, 7, 9],\n        [8, 8, 7, 8, 7]])\n\nEpoch 4\nNo. pseudo samples: 2\ntheoretical ratio of pseudo data included: 0.4\n% of pseudo data in the dataset: 0.2857142857142857\nDataset size: 7\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 7, 7, 7, 9],\n        [8, 8, 7, 8, 7]])\n\nEpoch 5\nNo. pseudo samples: 2\ntheoretical ratio of pseudo data included: 0.5\n% of pseudo data in the dataset: 0.2857142857142857\nDataset size: 7\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [7, 6, 8, 6, 7],\n        [9, 7, 7, 7, 9]])\n\nEpoch 6\nNo. pseudo samples: 3\ntheoretical ratio of pseudo data included: 0.6\n% of pseudo data in the dataset: 0.375\nDataset size: 8\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 7, 7, 7, 9],\n        [8, 8, 7, 8, 7],\n        [7, 6, 8, 6, 7]])\n\nEpoch 7\nNo. pseudo samples: 4\ntheoretical ratio of pseudo data included: 0.7\n% of pseudo data in the dataset: 0.4444444444444444\nDataset size: 9\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [8, 8, 7, 8, 7],\n        [9, 8, 8, 7, 8],\n        [8, 9, 9, 7, 9],\n        [7, 6, 8, 6, 7]])\n\nEpoch 8\nNo. pseudo samples: 4\ntheoretical ratio of pseudo data included: 0.8\n% of pseudo data in the dataset: 0.4444444444444444\nDataset size: 9\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 7, 7, 7, 9],\n        [8, 9, 9, 7, 9],\n        [7, 6, 8, 6, 7],\n        [9, 8, 8, 7, 8]])\n\nEpoch 9\nNo. pseudo samples: 4\ntheoretical ratio of pseudo data included: 0.9\n% of pseudo data in the dataset: 0.4444444444444444\nDataset size: 9\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 8, 8, 7, 8],\n        [8, 8, 7, 8, 7],\n        [8, 9, 9, 7, 9],\n        [9, 7, 7, 7, 9]])\n\nEpoch 10\nNo. pseudo samples: 5\ntheoretical ratio of pseudo data included: 1.0\n% of pseudo data in the dataset: 0.5\nDataset size: 10\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [7, 6, 8, 6, 7],\n        [9, 7, 7, 7, 9],\n        [8, 9, 9, 7, 9],\n        [9, 8, 8, 7, 8],\n        [8, 8, 7, 8, 7]])\n\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"data_loader_v2 = IncDataLoader(\n    labeled_data=labeled_data,\n    labels=labels,\n    pseudo_data=pseudo_data,\n    pseudo_labels=pseudo_labels,\n    n_epochs=10\n)\n\n# exponential growth of pseudo ratio\ndef exponential(step, loader):\n    if step == 0:\n        return 0\n    return 2 ** (step - 1) / loader.n_epochs\n\ndata_loader_v2.set_ratio_func(exponential)\n\nfor epoch in range(11):\n    data, labs = data_loader_v2()\n    print(\"Epoch\", epoch)\n    print(\"No. pseudo samples:\", data_loader_v2.get_pseudo_number())\n    print(\"Theoretical % of pseudo data utilized:\", data_loader_v2.get_pseudo_ratio() * 100)\n    print(\"% of pseudo data in the dataset:\", data_loader_v2.get_total_pseudo_ratio() * 100)\n    print(\"Dataset size:\", len(data))\n    print(data)\n    print()\n    data_loader_v2.update()","metadata":{"cell_id":"8d39256aec3e4a7cb30b02ba0d11870f","source_hash":"4ff709aa","execution_start":1683134464836,"execution_millis":19,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0\nNo. pseudo samples: 0\nTheoretical % of pseudo data utilized: 0\n% of pseudo data in the dataset: 0.0\nDataset size: 5\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0]])\n\nEpoch 1\nNo. pseudo samples: 0\nTheoretical % of pseudo data utilized: 10.0\n% of pseudo data in the dataset: 0.0\nDataset size: 5\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0]])\n\nEpoch 2\nNo. pseudo samples: 1\nTheoretical % of pseudo data utilized: 20.0\n% of pseudo data in the dataset: 16.666666666666664\nDataset size: 6\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 7, 7, 7, 9]])\n\nEpoch 3\nNo. pseudo samples: 2\nTheoretical % of pseudo data utilized: 40.0\n% of pseudo data in the dataset: 28.57142857142857\nDataset size: 7\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [7, 6, 8, 6, 7],\n        [9, 8, 8, 7, 8]])\n\nEpoch 4\nNo. pseudo samples: 4\nTheoretical % of pseudo data utilized: 80.0\n% of pseudo data in the dataset: 44.44444444444444\nDataset size: 9\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 8, 8, 7, 8],\n        [8, 9, 9, 7, 9],\n        [7, 6, 8, 6, 7],\n        [9, 7, 7, 7, 9]])\n\nEpoch 5\nNo. pseudo samples: 8\nTheoretical % of pseudo data utilized: 160.0\n% of pseudo data in the dataset: 80.0\nDataset size: 10\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [8, 9, 9, 7, 9],\n        [9, 8, 8, 7, 8],\n        [7, 6, 8, 6, 7],\n        [8, 8, 7, 8, 7],\n        [9, 7, 7, 7, 9]])\n\nEpoch 6\nNo. pseudo samples: 16\nTheoretical % of pseudo data utilized: 320.0\n% of pseudo data in the dataset: 160.0\nDataset size: 10\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 7, 7, 7, 9],\n        [9, 8, 8, 7, 8],\n        [7, 6, 8, 6, 7],\n        [8, 8, 7, 8, 7],\n        [8, 9, 9, 7, 9]])\n\nEpoch 7\nNo. pseudo samples: 32\nTheoretical % of pseudo data utilized: 640.0\n% of pseudo data in the dataset: 320.0\nDataset size: 10\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [8, 8, 7, 8, 7],\n        [7, 6, 8, 6, 7],\n        [8, 9, 9, 7, 9],\n        [9, 8, 8, 7, 8],\n        [9, 7, 7, 7, 9]])\n\nEpoch 8\nNo. pseudo samples: 64\nTheoretical % of pseudo data utilized: 1280.0\n% of pseudo data in the dataset: 640.0\nDataset size: 10\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [9, 8, 8, 7, 8],\n        [7, 6, 8, 6, 7],\n        [8, 9, 9, 7, 9],\n        [8, 8, 7, 8, 7],\n        [9, 7, 7, 7, 9]])\n\nEpoch 9\nNo. pseudo samples: 128\nTheoretical % of pseudo data utilized: 2560.0\n% of pseudo data in the dataset: 1280.0\nDataset size: 10\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [8, 8, 7, 8, 7],\n        [9, 7, 7, 7, 9],\n        [9, 8, 8, 7, 8],\n        [8, 9, 9, 7, 9],\n        [7, 6, 8, 6, 7]])\n\nEpoch 10\nNo. pseudo samples: 256\nTheoretical % of pseudo data utilized: 5120.0\n% of pseudo data in the dataset: 2560.0\nDataset size: 10\ntensor([[3, 4, 1, 3, 3],\n        [3, 0, 0, 3, 4],\n        [0, 4, 0, 0, 1],\n        [4, 2, 4, 2, 3],\n        [1, 3, 3, 1, 0],\n        [8, 8, 7, 8, 7],\n        [7, 6, 8, 6, 7],\n        [8, 9, 9, 7, 9],\n        [9, 8, 8, 7, 8],\n        [9, 7, 7, 7, 9]])\n\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b2f14aee-af04-4db5-af55-57a3a58b9f40' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"5a5fe60ac67c4d01b6673e57e1e8e6b7","deepnote_persisted_session":{"createdAt":"2023-05-03T17:46:25.128Z"},"deepnote_execution_queue":[]}}