{"cells":[{"cell_type":"code","source":"import numpy as np\nimport codecs\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom torch import Tensor, nn\nimport random\n\n# Ensuring reproducibility\nseed = 0\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(seed)\nrandom.seed(seed)\n\nimport sys\nsys.path.insert(1, '/work/nlp-project')\nfrom scripts.read_write_data import load_data\nfrom models.classes import DataIterator, Batch, F1_evaluator, Train1BiLSTM\n\nimport gensim.models\nGoogleEmbs = gensim.models.KeyedVectors.load_word2vec_format(\n                                '/work/nlp-project/models/GoogleNews-50k.bin', binary=True)","metadata":{"cell_id":"e9c55cd703934845b84e15b34b335fbf","source_hash":"1a4a39e1","execution_start":1685013090026,"execution_millis":29269,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"code","source":"TRAIN_PATH = \"nlp-project/data/processed/train_splits/labeled.conll\"\nDEV_PATH = \"nlp-project/data/processed/dev.conll\"\nTEST_PATH  = \"nlp-project/data/processed/test.conll\"\n\nx_train, y_train, bio_train, domain_train = load_data(TRAIN_PATH)\nx_dev, y_dev, bio_dev, domain_dev = load_data(DEV_PATH)\nx_test, y_test, bio_test, domain_test = load_data(TEST_PATH)","metadata":{"cell_id":"8222c72815f2489888206b9ff32369e8","source_hash":"9fa1a1f","execution_start":1685013119302,"execution_millis":973,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"model = Train1BiLSTM(hidden_size=10)\nmodel.fit(train=(x_train, y_train), \n          dev=(x_dev, y_dev), \n          print_metrics=False, \n          learning_rate=0.01, \n          epochs=20)","metadata":{"cell_id":"f0fb687b13bc493f8d9573017965d427","source_hash":"151124df","execution_start":1685015410918,"execution_millis":2772567,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0, train: 0.000, dev: 0.000\nEpoch 1, train: 0.000, dev: 0.000\nEpoch 2, train: 0.000, dev: 0.000\nEpoch 3, train: 0.000, dev: 0.000\nEpoch 4, train: 0.389, dev: 0.620\nEpoch 5, train: 0.710, dev: 0.653\nEpoch 6, train: 0.737, dev: 0.654\nEpoch 7, train: 0.747, dev: 0.653\nEpoch 8, train: 0.753, dev: 0.651\nEpoch 9, train: 0.758, dev: 0.651\nEpoch 10, train: 0.762, dev: 0.654\nEpoch 11, train: 0.764, dev: 0.655\nEpoch 12, train: 0.766, dev: 0.651\nEpoch 13, train: 0.769, dev: 0.653\nEpoch 14, train: 0.769, dev: 0.657\nEpoch 15, train: 0.773, dev: 0.650\nEpoch 16, train: 0.776, dev: 0.661\nEpoch 17, train: 0.786, dev: 0.656\nEpoch 18, train: 0.797, dev: 0.670\nEpoch 19, train: 0.806, dev: 0.671\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model.train_f1_log, model.dev_f1_log","metadata":{"cell_id":"26544823d60449afac6e7908ac3e5257","source_hash":"7730da","execution_start":1685018331763,"execution_millis":7,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"([0,\n  0,\n  0,\n  0,\n  0.3892345986309894,\n  0.7102990033222591,\n  0.7369237588652483,\n  0.7471672961564098,\n  0.7531083481349911,\n  0.7584063921873265,\n  0.7616511318242343,\n  0.7643142476697736,\n  0.7661746753967373,\n  0.7690084481991996,\n  0.7694188243138127,\n  0.7732532265242545,\n  0.7764286509969923,\n  0.7858022617847946,\n  0.7966767710789266,\n  0.806484295845998],\n [0,\n  0,\n  0,\n  0,\n  0.6204238921001927,\n  0.6534351145038167,\n  0.6539488744753911,\n  0.6534954407294833,\n  0.6513726965024446,\n  0.6505111700113593,\n  0.6539488744753911,\n  0.6554105909439755,\n  0.6509146341463414,\n  0.6528258362168398,\n  0.6569230769230769,\n  0.6496766831494866,\n  0.6612716763005779,\n  0.6559633027522935,\n  0.6700310559006212,\n  0.6713395638629284])"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Epoch 0, train: 0.000, dev: 0.000\n# Epoch 1, train: 0.000, dev: 0.000\n# Epoch 2, train: 0.437, dev: 0.609\n# Epoch 3, train: 0.685, dev: 0.630\n# Epoch 4, train: 0.707, dev: 0.639\n# Epoch 5, train: 0.716, dev: 0.640\n# Epoch 6, train: 0.723, dev: 0.639\n# Epoch 7, train: 0.733, dev: 0.651\n# Epoch 8, train: 0.747, dev: 0.650\n# Epoch 9, train: 0.760, dev: 0.648\n# Epoch 10, train: 0.769, dev: 0.643\n# Epoch 11, train: 0.779, dev: 0.644\n# Epoch 12, train: 0.786, dev: 0.646\n# Epoch 13, train: 0.792, dev: 0.631\n# Epoch 14, train: 0.798, dev: 0.640","metadata":{"cell_id":"650b3e3c3bd64b29959a043eac50b173","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = BaselineBiLSTM(hidden_size=10)\n# model.fit(x_train, y_train, dev=(x_dev, y_dev), \n#           print_metrics=False, \n#           learning_rate=0.001, \n#           epochs=20)","metadata":{"cell_id":"a79684ee9d3047e89470dd97f82b2f38","source_hash":"3cdae577","execution_start":1683643767565,"execution_millis":261638,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0, train: 0.005, dev: 0.000\nEpoch 1, train: 0.000, dev: 0.000\nEpoch 2, train: 0.000, dev: 0.000\nEpoch 3, train: 0.153, dev: 0.726\nEpoch 4, train: 0.821, dev: 0.780\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nhidden_size=5, lr=0.05 --- Epoch 22, train: 0.861, dev: 0.774\nhidden_size=10, lr=0.05 --- Epoch 22, train: 0.849, dev: 0.780\nhidden_size=10, lr=0.05 --- Epoch 9, train: 0.849, dev: 0.778\nhidden_size=9, lr=0.01 --- Epoch 25, train: 0.919, dev: 0.800\n\nsource for saving and loading: https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\n\"\"\"","metadata":{"cell_id":"e2396bd933e941f38662e5f076283344","source_hash":"ec224cd4","execution_start":1683644029206,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"'\\nhidden_size=5, lr=0.05 --- Epoch 22, train: 0.861, dev: 0.774\\nhidden_size=10, lr=0.05 --- Epoch 22, train: 0.849, dev: 0.780\\nhidden_size=10, lr=0.05 --- Epoch 9, train: 0.849, dev: 0.778\\nhidden_size=9, lr=0.01 --- Epoch 25, train: 0.919, dev: 0.800\\n\\nsource for saving and loading: https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\\n'"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"Saving and loading model:","metadata":{"cell_id":"f200115a7e0f4ce3abc78338b39ef9a5","formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"SAVE_PATH = \"/work/nlp-project/models/Baseline.pt\"\n# torch.save(model, SAVE_PATH)","metadata":{"cell_id":"330fbf14501545f0b5e891378af7aa90","source_hash":"daf7ccf","execution_start":1685018347031,"execution_millis":11,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model2 = torch.load(SAVE_PATH)","metadata":{"cell_id":"f57d41510ff643b6a69aafed603c6438","source_hash":"6a009955","execution_start":1685018399266,"execution_millis":14,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"code","source":"baseline_errors = model2.evaluate(x_dev, y_dev, bio_dev, domain_dev)","metadata":{"cell_id":"b15337c51dbc4c8db43ef9b15e6e73a5","source_hash":"1f470f5d","execution_start":1685018519103,"execution_millis":68876,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"F1: 0.671 precision: 0.718 recall: 0.630\nMetrics: 1200 ACT, 1368 POS, 862 COR, 432 INC (206 PAR, 300 MIS, 132 SPU)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model2.fit(train=(x_train, y_train), \n          dev=(x_dev, y_dev), \n          print_metrics=False, \n          learning_rate=0.01, \n          epochs=5)","metadata":{"cell_id":"f9651db0d28c40ffa06915df9b3774c8","source_hash":"b046f42","execution_start":1685018720799,"execution_millis":363503,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 0, train: 0.811, dev: 0.666\nEpoch 1, train: 0.819, dev: 0.656\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_dev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mprint_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/work/nlp-project/models/classes.py:356\u001b[0m, in \u001b[0;36mTrain1BiLSTM.fit\u001b[0;34m(self, train, dev, epochs, print_metrics, learning_rate)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_iterator(padded_documents, padded_labels)):\n\u001b[0;32m--> 356\u001b[0m     pred_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# pred_tags = pred_tags.view(-1, self.n_labels) # probability distribution for each tag across all words in batch\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch\u001b[38;5;241m.\u001b[39mtargets)  \u001b[38;5;66;03m# \u001b[39;00m\n","File \u001b[0;32m/work/nlp-project/models/classes.py:322\u001b[0m, in \u001b[0;36mTrain1BiLSTM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03mImplements a forward pass through the BiLSTM.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03minputs are a batch (list) of sentences.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    321\u001b[0m word_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_google_embeds(inputs)\n\u001b[0;32m--> 322\u001b[0m lstm_result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_embeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_result)\n\u001b[1;32m    324\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(tags, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/modules/rnn.py:769\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    773\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":12},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b2f14aee-af04-4db5-af55-57a3a58b9f40' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"f4ea3efeacac4b9c91ee18c52bf4c859","deepnote_execution_queue":[]}}